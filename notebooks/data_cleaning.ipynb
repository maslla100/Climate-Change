{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Data Cleaning Notebook\n",
                "This notebook is used to clean the datasets for global temperature anomalies and related information."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 71,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Step 1: Import Required Libraries\n",
                "import pandas as pd\n",
                "import numpy as np"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Step 2: Load the Datasets\n",
                "This step will load the raw datasets and handle the first row as a potential title."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 74,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Attempting to load ../data/raw/Globalmonthlyandseasonal.csv...\n",
                        "First row contains a title in ../data/raw/Globalmonthlyandseasonal.csv. Skipping the first row.\n",
                        "Attempting to load ../data/raw/NorthernHemisphere.csv...\n",
                        "First row contains a title in ../data/raw/NorthernHemisphere.csv. Skipping the first row.\n",
                        "Attempting to load ../data/raw/SouthernHemisphere.csv...\n",
                        "First row contains a title in ../data/raw/SouthernHemisphere.csv. Skipping the first row.\n",
                        "Attempting to load ../data/raw/ZoneAnnual.csv...\n",
                        "First row is not a title in ../data/raw/ZoneAnnual.csv. Proceeding as normal.\n",
                        "   Year   Jan   Feb   Mar   Apr   May   Jun   Jul   Aug   Sep   Oct   Nov  \\\n",
                        "0  1880 -0.20 -0.25 -0.09 -0.16 -0.09 -0.22 -0.20 -0.09  -.15  -.22  -.22   \n",
                        "1  1881 -0.19 -0.15  0.02  0.04  0.07 -0.19  0.01 -0.04  -.16  -.22  -.18   \n",
                        "2  1882  0.16  0.14  0.05 -0.15 -0.13 -0.22 -0.16 -0.07  -.14  -.23  -.17   \n",
                        "3  1883 -0.29 -0.36 -0.12 -0.18 -0.18 -0.07 -0.07 -0.14  -.22  -.11  -.24   \n",
                        "4  1884 -0.12 -0.08 -0.36 -0.40 -0.33 -0.35 -0.30 -0.28  -.27  -.25  -.33   \n",
                        "\n",
                        "    Dec   J-D   D-N   DJF   MAM   JJA   SON  \n",
                        "0  -.18  -.17   ***   *** -0.11 -0.17  -.20  \n",
                        "1  -.07  -.09  -.10  -.18  0.04 -0.07  -.19  \n",
                        "2  -.36  -.11  -.08   .08 -0.08 -0.15  -.18  \n",
                        "3  -.11  -.17  -.20  -.34 -0.16 -0.09  -.19  \n",
                        "4  -.30  -.28  -.27  -.10 -0.36 -0.31  -.28  \n",
                        "   Year   Jan   Feb   Mar   Apr   May   Jun   Jul   Aug   Sep   Oct   Nov  \\\n",
                        "0  1880 -0.39 -0.53 -0.23 -0.30 -0.05 -0.18 -0.22 -0.25  -.25  -.30  -.43   \n",
                        "1  1881 -0.30 -0.25 -0.06 -0.02  0.05 -0.34  0.09 -0.05  -.28  -.45  -.37   \n",
                        "2  1882  0.26  0.21  0.02 -0.29 -0.22 -0.28 -0.28 -0.14  -.24  -.51  -.34   \n",
                        "3  1883 -0.57 -0.65 -0.15 -0.29 -0.25 -0.11 -0.06 -0.22  -.34  -.16  -.44   \n",
                        "4  1884 -0.15 -0.10 -0.64 -0.59 -0.35 -0.41 -0.41 -0.51  -.45  -.45  -.57   \n",
                        "\n",
                        "    Dec   J-D   D-N   DJF   MAM   JJA   SON  \n",
                        "0  -.42  -.30   ***   *** -0.20 -0.22  -.33  \n",
                        "1  -.23  -.19  -.20  -.33 -0.01 -0.10  -.37  \n",
                        "2  -.68  -.21  -.17   .08 -0.16 -0.23  -.36  \n",
                        "3  -.15  -.28  -.33  -.64 -0.23 -0.13  -.31  \n",
                        "4  -.46  -.42  -.40  -.14 -0.53 -0.44  -.49  \n",
                        "   Year   Jan   Feb   Mar   Apr   May   Jun   Jul   Aug   Sep   Oct   Nov  \\\n",
                        "0  1880  0.00  0.03  0.06 -0.02 -0.13 -0.25 -0.17  0.06  -.05  -.15   .00   \n",
                        "1  1881 -0.09 -0.06  0.09  0.09  0.08 -0.05 -0.08 -0.02  -.04  -.01  -.01   \n",
                        "2  1882  0.06  0.07  0.07 -0.02 -0.04 -0.15 -0.05  0.01  -.05   .03  -.02   \n",
                        "3  1883 -0.03 -0.09 -0.09 -0.08 -0.10 -0.02 -0.09 -0.05  -.11  -.06  -.05   \n",
                        "4  1884 -0.09 -0.06 -0.10 -0.22 -0.32 -0.29 -0.22 -0.07  -.11  -.07  -.11   \n",
                        "\n",
                        "    Dec   J-D   D-N   DJF   MAM   JJA   SON  \n",
                        "0   .05  -.05   ***   *** -0.03 -0.12  -.07  \n",
                        "1   .09   .00   .00  -.03  0.09 -0.05  -.02  \n",
                        "2  -.08  -.01   .00   .07  0.00 -0.06  -.01  \n",
                        "3  -.06  -.07  -.07  -.06 -0.09 -0.05  -.07  \n",
                        "4  -.15  -.15  -.14  -.07 -0.21 -0.19  -.10  \n",
                        "   Year  Glob  NHem  SHem  24N-90N  24S-24N  90S-24S  64N-90N  44N-64N  \\\n",
                        "0  1880 -0.17 -0.30 -0.05    -0.40    -0.12    -0.02    -0.82    -0.51   \n",
                        "1  1881 -0.09 -0.19  0.00    -0.37     0.11    -0.08    -0.93    -0.47   \n",
                        "2  1882 -0.11 -0.21 -0.01    -0.32    -0.04     0.00    -1.41    -0.29   \n",
                        "3  1883 -0.17 -0.28 -0.07    -0.36    -0.16    -0.02    -0.18    -0.57   \n",
                        "4  1884 -0.28 -0.42 -0.15    -0.61    -0.14    -0.14    -1.30    -0.65   \n",
                        "\n",
                        "   24N-44N  EQU-24N  24S-EQU  44S-24S  64S-44S  90S-64S  \n",
                        "0    -0.31    -0.13    -0.10    -0.05     0.05     0.68  \n",
                        "1    -0.22     0.11     0.11    -0.07    -0.07     0.61  \n",
                        "2    -0.15    -0.02    -0.05     0.00     0.04     0.64  \n",
                        "3    -0.28    -0.16    -0.15    -0.05     0.07     0.51  \n",
                        "4    -0.47    -0.11    -0.17    -0.20    -0.02     0.66  \n"
                    ]
                }
            ],
            "source": [
                "def load_and_clean_csv(file_path):\n",
                "    try:\n",
                "        # Step 1: Try loading the file with no headers, inspect the first few rows\n",
                "        print(f\"Attempting to load {file_path}...\")\n",
                "        df = pd.read_csv(file_path, header=None, delimiter=',', on_bad_lines='skip', engine='python')\n",
                "        \n",
                "        # Step 2: Check if the first row contains a title (e.g., 'Land-Ocean: Global Means')\n",
                "        first_row = df.iloc[0, 0]\n",
                "        \n",
                "        if isinstance(first_row, str) and \"Land-Ocean\" in first_row:\n",
                "            print(f\"First row contains a title in {file_path}. Skipping the first row.\")\n",
                "            # Reload the file, skipping the first row and using the second row as the header\n",
                "            df = pd.read_csv(file_path, header=1, delimiter=',', on_bad_lines='skip', engine='python')\n",
                "        else:\n",
                "            print(f\"First row is not a title in {file_path}. Proceeding as normal.\")\n",
                "            df = pd.read_csv(file_path, header=0, delimiter=',', on_bad_lines='skip', engine='python')\n",
                "        return df\n",
                "    except pd.errors.ParserError as e:\n",
                "        print(f\"Error parsing {file_path}: {e}\")\n",
                "        return None\n",
                "    except Exception as e:\n",
                "        print(f\"An unexpected error occurred while parsing {file_path}: {e}\")\n",
                "        return None\n",
                "\n",
                "# Load datasets\n",
                "global_monthly = load_and_clean_csv(\"../data/raw/Globalmonthlyandseasonal.csv\")\n",
                "northern_hemisphere = load_and_clean_csv(\"../data/raw/NorthernHemisphere.csv\")\n",
                "southern_hemisphere = load_and_clean_csv(\"../data/raw/SouthernHemisphere.csv\")\n",
                "zone_annual = load_and_clean_csv(\"../data/raw/ZoneAnnual.csv\")\n",
                "\n",
                "# Print first few rows to confirm\n",
                "if global_monthly is not None:\n",
                "    print(global_monthly.head())\n",
                "if northern_hemisphere is not None:\n",
                "    print(northern_hemisphere.head())\n",
                "if southern_hemisphere is not None:\n",
                "    print(southern_hemisphere.head())\n",
                "if zone_annual is not None:\n",
                "    print(zone_annual.head())"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Step 3: Handle Missing Values\n",
                "Replace placeholder values such as '***' with `NaN`."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 75,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Handle missing values by replacing '***' with NaN\n",
                "datasets = [global_monthly, northern_hemisphere, southern_hemisphere, zone_annual]\n",
                "\n",
                "for dataset in datasets:\n",
                "    dataset.replace(\"***\", np.nan, inplace=True)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Step 4: Ensure Correct Data Types\n",
                "Ensure the `Year` column is of integer type and check the data types of other columns."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 76,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "<class 'pandas.core.frame.DataFrame'>\n",
                        "RangeIndex: 145 entries, 0 to 144\n",
                        "Data columns (total 19 columns):\n",
                        " #   Column  Non-Null Count  Dtype  \n",
                        "---  ------  --------------  -----  \n",
                        " 0   Year    145 non-null    Int64  \n",
                        " 1   Jan     145 non-null    float64\n",
                        " 2   Feb     145 non-null    float64\n",
                        " 3   Mar     145 non-null    float64\n",
                        " 4   Apr     145 non-null    float64\n",
                        " 5   May     145 non-null    float64\n",
                        " 6   Jun     145 non-null    float64\n",
                        " 7   Jul     145 non-null    float64\n",
                        " 8   Aug     145 non-null    float64\n",
                        " 9   Sep     144 non-null    object \n",
                        " 10  Oct     144 non-null    object \n",
                        " 11  Nov     144 non-null    object \n",
                        " 12  Dec     144 non-null    object \n",
                        " 13  J-D     144 non-null    object \n",
                        " 14  D-N     143 non-null    object \n",
                        " 15  DJF     144 non-null    object \n",
                        " 16  MAM     145 non-null    float64\n",
                        " 17  JJA     145 non-null    float64\n",
                        " 18  SON     144 non-null    object \n",
                        "dtypes: Int64(1), float64(10), object(8)\n",
                        "memory usage: 21.8+ KB\n",
                        "None\n",
                        "<class 'pandas.core.frame.DataFrame'>\n",
                        "RangeIndex: 145 entries, 0 to 144\n",
                        "Data columns (total 19 columns):\n",
                        " #   Column  Non-Null Count  Dtype  \n",
                        "---  ------  --------------  -----  \n",
                        " 0   Year    145 non-null    Int64  \n",
                        " 1   Jan     145 non-null    float64\n",
                        " 2   Feb     145 non-null    float64\n",
                        " 3   Mar     145 non-null    float64\n",
                        " 4   Apr     145 non-null    float64\n",
                        " 5   May     145 non-null    float64\n",
                        " 6   Jun     145 non-null    float64\n",
                        " 7   Jul     145 non-null    float64\n",
                        " 8   Aug     145 non-null    float64\n",
                        " 9   Sep     144 non-null    object \n",
                        " 10  Oct     144 non-null    object \n",
                        " 11  Nov     144 non-null    object \n",
                        " 12  Dec     144 non-null    object \n",
                        " 13  J-D     144 non-null    object \n",
                        " 14  D-N     143 non-null    object \n",
                        " 15  DJF     144 non-null    object \n",
                        " 16  MAM     145 non-null    float64\n",
                        " 17  JJA     145 non-null    float64\n",
                        " 18  SON     144 non-null    object \n",
                        "dtypes: Int64(1), float64(10), object(8)\n",
                        "memory usage: 21.8+ KB\n",
                        "None\n",
                        "<class 'pandas.core.frame.DataFrame'>\n",
                        "RangeIndex: 145 entries, 0 to 144\n",
                        "Data columns (total 19 columns):\n",
                        " #   Column  Non-Null Count  Dtype  \n",
                        "---  ------  --------------  -----  \n",
                        " 0   Year    145 non-null    Int64  \n",
                        " 1   Jan     145 non-null    float64\n",
                        " 2   Feb     145 non-null    float64\n",
                        " 3   Mar     145 non-null    float64\n",
                        " 4   Apr     145 non-null    float64\n",
                        " 5   May     145 non-null    float64\n",
                        " 6   Jun     145 non-null    float64\n",
                        " 7   Jul     145 non-null    float64\n",
                        " 8   Aug     145 non-null    float64\n",
                        " 9   Sep     144 non-null    object \n",
                        " 10  Oct     144 non-null    object \n",
                        " 11  Nov     144 non-null    object \n",
                        " 12  Dec     144 non-null    object \n",
                        " 13  J-D     144 non-null    object \n",
                        " 14  D-N     143 non-null    object \n",
                        " 15  DJF     144 non-null    object \n",
                        " 16  MAM     145 non-null    float64\n",
                        " 17  JJA     145 non-null    float64\n",
                        " 18  SON     144 non-null    object \n",
                        "dtypes: Int64(1), float64(10), object(8)\n",
                        "memory usage: 21.8+ KB\n",
                        "None\n",
                        "<class 'pandas.core.frame.DataFrame'>\n",
                        "RangeIndex: 144 entries, 0 to 143\n",
                        "Data columns (total 15 columns):\n",
                        " #   Column   Non-Null Count  Dtype  \n",
                        "---  ------   --------------  -----  \n",
                        " 0   Year     144 non-null    Int64  \n",
                        " 1   Glob     144 non-null    float64\n",
                        " 2   NHem     144 non-null    float64\n",
                        " 3   SHem     144 non-null    float64\n",
                        " 4   24N-90N  144 non-null    float64\n",
                        " 5   24S-24N  144 non-null    float64\n",
                        " 6   90S-24S  144 non-null    float64\n",
                        " 7   64N-90N  144 non-null    float64\n",
                        " 8   44N-64N  144 non-null    float64\n",
                        " 9   24N-44N  144 non-null    float64\n",
                        " 10  EQU-24N  144 non-null    float64\n",
                        " 11  24S-EQU  144 non-null    float64\n",
                        " 12  44S-24S  144 non-null    float64\n",
                        " 13  64S-44S  144 non-null    float64\n",
                        " 14  90S-64S  144 non-null    float64\n",
                        "dtypes: Int64(1), float64(14)\n",
                        "memory usage: 17.1 KB\n",
                        "None\n"
                    ]
                }
            ],
            "source": [
                "for dataset in datasets:\n",
                "    if 'Year' in dataset.columns:\n",
                "        # Convert 'Year' to numeric, setting errors='coerce' to turn non-numeric entries into NaN\n",
                "        dataset['Year'] = pd.to_numeric(dataset['Year'], errors='coerce')\n",
                "        \n",
                "        # Drop rows where 'Year' is NaN (i.e., where conversion failed)\n",
                "        dataset.dropna(subset=['Year'], inplace=True)\n",
                "        \n",
                "        # Convert 'Year' to integers, using Int64 which allows for missing data if any exists\n",
                "        dataset['Year'] = dataset['Year'].astype('Int64')\n",
                "    \n",
                "    # Print dataset info for debugging\n",
                "    print(dataset.info())"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Step 5: Handle Duplicates\n",
                "Remove any duplicate rows in the datasets."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 77,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Drop duplicate rows\n",
                "for dataset in datasets:\n",
                "    dataset.drop_duplicates(inplace=True)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Step 6: Validate Year Ranges\n",
                "Remove rows where the `Year` value is outside the expected range (1880-2023)."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 78,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Keep only rows where 'Year' is between 1880 and 2023\n",
                "for i in range(len(datasets)):\n",
                "    if 'Year' in datasets[i].columns:\n",
                "        datasets[i] = datasets[i][(datasets[i]['Year'] >= 1880) & (datasets[i]['Year'] <= 2023)]"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Step 7: Fill Missing Values\n",
                "For missing temperature data, fill the gaps using the column means."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 79,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "/var/folders/sd/7ryt1xgs2sg3bxmccx2f715c0000gn/T/ipykernel_83768/373111762.py:4: SettingWithCopyWarning: \n",
                        "A value is trying to be set on a copy of a slice from a DataFrame.\n",
                        "Try using .loc[row_indexer,col_indexer] = value instead\n",
                        "\n",
                        "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
                        "  dataset[num_cols] = dataset[num_cols].fillna(dataset[num_cols].mean())\n"
                    ]
                }
            ],
            "source": [
                "# Fill missing values with column means\n",
                "for dataset in datasets:\n",
                "    num_cols = dataset.select_dtypes(include=[np.number]).columns\n",
                "    dataset[num_cols] = dataset[num_cols].fillna(dataset[num_cols].mean())"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Step 8: Save Cleaned Datasets\n",
                "Save the cleaned datasets to new CSV files."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 80,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Save cleaned data\n",
                "global_monthly.to_csv(\"../data/cleaned/cleaned_globalmonthlyandseasonal.csv\", index=False)\n",
                "northern_hemisphere.to_csv(\"../data/cleaned/cleaned_northernhemisphere.csv\", index=False)\n",
                "southern_hemisphere.to_csv(\"../data/cleaned/cleaned_southernhemisphere.csv\", index=False)\n",
                "zone_annual.to_csv(\"../data/cleaned/cleaned_zoneannual.csv\", index=False)"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "name": "python",
            "version": "3.10.14"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
